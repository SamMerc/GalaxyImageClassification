{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GOAL OF THIS FILE\n",
    "This code will ideally be used for the unsupervised training algorithm (in this case, K-means), which generates a bank of filters D\n",
    "extract 16-by-16 pixel grayscale patches represented as a vector of 256 pixel intensities\n",
    "I.E. Crop and scale images while keeping RGB channels \n",
    "\n",
    "FOR THIS FILE WE ARE ATTEMPTING TO NORMALIZE AND WHITEN OUR PATCHES\n",
    "Implementing method outlined in this paper:\n",
    "https://www-cs.stanford.edu/~acoates/papers/coatesng_nntot2012.pdf\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from cv2 import cv2 #Use 'pip install opencv-python' to get module if you don't have it\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetImage(object):\n",
    "    #Load raw image files\n",
    "    \n",
    "    #initialize the path (TODO - make basepath an input parameter, don't hardcode too much)\n",
    "\n",
    "    #Data should be stored in Users/YOUR_USER_NAME/321_galaxies/images_training_rev1\n",
    "    def __init__(self, username, num_pics=10):\n",
    "\n",
    "        self.basepath = '/Users/'+username+'/321_galaxies/'\n",
    "        self.imPath_test = 'images_test_rev1/'\n",
    "        self.imPath_training =  'images_training_rev1/'\n",
    "       \n",
    "        #create variable that stores the image\n",
    "        self.images = []\n",
    "        i=0\n",
    "        for filename in glob.glob(self.basepath + self.imPath_training+'*.jpg'): #assuming jpg\n",
    "            if(i >= num_pics):\n",
    "                break\n",
    "            im=cv2.imread(filename)\n",
    "            self.images.append(im)\n",
    "            i +=1 \n",
    "        self.cropped_images = []\n",
    "        self.scaled_images = []\n",
    "        self.patches = []\n",
    "       \n",
    "\n",
    "    #Crop image from 424x424 to 160x160. To do we crop axes from {x=0, y=0, x=424, y=424 } => {x=132, y=132, x=292, 400=292}\n",
    "    def crop(self, pixels_to_keep = 160):\n",
    "        for galaxyPic in self.images:\n",
    "            #Cast as int in order to use variables in the slicing indices\n",
    "            center = int(424/2)\n",
    "            dim = int(pixels_to_keep/2)\n",
    "            cropmin = center - dim\n",
    "            cropmax = center + dim\n",
    "            self.cropped_images.append(galaxyPic[cropmin:cropmax, cropmin:cropmax])\n",
    "        return self\n",
    "\n",
    "    #function that takes an image and scales the entire image to its new size (unlike crop, image stays intact). \n",
    "    def scale(self, new_size = 16):\n",
    "        for galaxyPic in self.cropped_images:\n",
    "            dimensions = (int(new_size), int(new_size))\n",
    "            self.scaled_images.append(cv2.resize(galaxyPic, dimensions))\n",
    "        return self\n",
    "    \n",
    "    #function that crops out random 4x4 patches of an image.\n",
    "    def patch(self, p_size=4, num_patches_per_image = 5):\n",
    "        for i in range(0, num_patches_per_image):\n",
    "            for galaxyPic in self.scaled_images:\n",
    "                patch_x = np.random.randint(2, 14)\n",
    "                patch_y = np.random.randint(2, 14)\n",
    "                dim = int(p_size/2)\n",
    "                patchminx = patch_x - dim\n",
    "                patchminy = patch_y - dim\n",
    "                patchmaxx = patch_x + dim\n",
    "                patchmaxy = patch_y + dim\n",
    "                self.patches.append(galaxyPic[patchminx:patchmaxx, patchminy:patchmaxy])\n",
    "        self.patches = np.vstack(self.patches)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the class by creating a 'galaxyPic' object, cropping it, scaling it, and saving the new image\n",
    "galaxyPics = GetImage('samsonmercier/Desktop')\n",
    "galaxyPics.crop()\n",
    "galaxyPics.scale()\n",
    "galaxyPics.patch()\n",
    "\n",
    "i=0\n",
    "\n",
    "for patch in galaxyPics.patches:\n",
    "    cv2.imwrite(\"patches/patchno\"+str(i)+\".jpg\", patch)\n",
    "    i += 1\n",
    "    #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that normalizes the pixels. Takes vstack of patches as input\n",
    "def normalization(patches):\n",
    "    patches = patches.astype('float32')\n",
    "    for i in range(len(patches)):\n",
    "        patch_mean = np.mean(patches[i], axis=(0,1))\n",
    "        patch_var = np.std(patches[i], axis=(0,1))**2\n",
    "        patches[i] = (patches[i] - patch_mean) / np.sqrt(patch_var+10)\n",
    "    return patches\n",
    "\n",
    "## Function that runs ZCA whitening\n",
    "def whiten(patches):\n",
    "    for i in range(len(patches)):\n",
    "        patch_cov = np.cov(patches[i], rowvar=0)\n",
    "        patch_mean = np.mean(patches[i], axis=(0,1))\n",
    "        d, v = np.linalg.eig(patch_cov)\n",
    "        p = np.dot(v, np.dot(np.diag(np.sqrt(1 / (d + 0.1))), v.T))\n",
    "        patches[i] = np.dot(patches[i] - patch_mean, p)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4, 3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels = normalization(galaxyPics.patches)\n",
    "new_pixels = whiten(pixels)\n",
    "pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.3893983  -1.7513521   2.8360186 ]\n",
      " [-1.2647171   0.05212893  2.5971808 ]\n",
      " [-2.1905177  -0.60810196  2.1198492 ]\n",
      " [-2.5344088  -1.2762433   1.1406269 ]]\n"
     ]
    }
   ],
   "source": [
    "print(new_pixels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To avoid empty clusters eed to initialize clusters from a Normal distribution \n",
    "#and normalize them to unit length?\n",
    "def Kmeans(L, k = 200, iters = 20, batch_size = 300):\n",
    "    L2 = np.sum(L**2, 1, keepdims=True)\n",
    "    #initialize centroids\n",
    "    centroids = np.random.randn(k, L.shape[1], L.shape[2]) * 0.1\n",
    "    for iteration in range(1, iters+1):\n",
    "        c2 = np.sum(centroids**2, 1, keepdims=True)\n",
    "        summation = np.zeros((k, L.shape[1], L.shape[2]))\n",
    "        counts = np.zeros((k, 1))\n",
    "        loss = 0\n",
    "        for i in range(0, L.shape[0], batch_size):\n",
    "            last_index = min(i + batch_size, L.shape[0])\n",
    "            m = last_index - i\n",
    "\n",
    "            # shape (k, batch_size) - shape (k, 1)\n",
    "            tmp = np.dot(centroids, L[i:last_index].T) - c2\n",
    "            # shape (batch_size, )\n",
    "            indices = np.argmax(tmp, 0)\n",
    "            # shape (1, batch_size)\n",
    "            val = np.max(tmp, 0, keepdims=True)\n",
    "\n",
    "            loss += np.sum((0.5 * L2[i:last_index]) - val.T)\n",
    "\n",
    "            # Don't use a sparse matrix here\n",
    "            S = np.zeros((batch_size, k))\n",
    "            S[range(batch_size), indices] = 1\n",
    "\n",
    "            # shape (k, n_pixels)\n",
    "            this_sum = np.dot(S.T, L[i:last_index, :])\n",
    "            summation += this_sum\n",
    "\n",
    "            this_counts = np.sum(S, 0, keepdims=True).T\n",
    "            counts += this_counts \n",
    "            \n",
    "        centroids = summation / counts\n",
    "        \n",
    "        bad_indices = np.where(counts == 0)[0]\n",
    "        centroids[bad_indices, :] = 0\n",
    "\n",
    "        assert not np.any(np.isnan(centroids))\n",
    "    return centroids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
