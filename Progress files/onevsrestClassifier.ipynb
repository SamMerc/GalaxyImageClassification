{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-d40bd5ffccd3>:156: RuntimeWarning: invalid value encountered in true_divide\n",
      "  centroids = summation / counts\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GOAL OF THIS FILE\n",
    "This code will ideally be used for the unsupervised training algorithm (in this case, K-means), which generates a bank of filters D\n",
    "extract 16-by-16 pixel grayscale patches represented as a vector of 256 pixel intensities\n",
    "I.E. Crop and scale images while keeping RGB channels \n",
    "\n",
    "FOR THIS FILE WE ARE ATTEMPTING TO TRAIN OUR MODEL AFTER GETTING OUR FEATURES\n",
    "Implementing method outlined in this paper:\n",
    "https://www-cs.stanford.edu/~acoates/papers/coatesng_nntot2012.pdf\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from cv2 import cv2 #Use 'pip install opencv-python' to get module if you don't have it\n",
    "import glob\n",
    "import os\n",
    "\n",
    "class GetImage(object):\n",
    "    #Load raw image files\n",
    "    \n",
    "    #initialize the path (TODO - make basepath an input parameter, don't hardcode too much)\n",
    "\n",
    "    #Data should be stored in Users/YOUR_USER_NAME/321_galaxies/images_training_rev1\n",
    "    def __init__(self, num_pics=10000, username='samsonmercier/Desktop'):\n",
    "\n",
    "        self.basepath = '/Users/'+username+'/321_galaxies/'\n",
    "        self.imPath_test = 'images_test_rev1/'\n",
    "        self.imPath_training =  'images_training_rev1/'\n",
    "        self.solPath = 'training_solutions_rev1.csv'\n",
    "        self.solutions=np.loadtxt(self.basepath + self.solPath, delimiter=',', skiprows=1)[:num_pics, 1:4]\n",
    "       \n",
    "        #create variable that stores the image\n",
    "        self.images = []\n",
    "        i=0\n",
    "        for filename in glob.glob(self.basepath + self.imPath_training+'*.jpg'): #assuming jpg\n",
    "            if(i >= num_pics):\n",
    "                break\n",
    "            im=cv2.imread(filename)\n",
    "            self.images.append(im)\n",
    "            i +=1 \n",
    "        self.cropped_images = []\n",
    "        self.scaled_images = []\n",
    "        self.patches = []\n",
    "       \n",
    "    #Get category labels for each image from the solutions file\n",
    "    def getLabels(self):\n",
    "        self.label=[]\n",
    "        for i in self.solutions:\n",
    "            self.m = np.where(i == max(i))[0][0]\n",
    "            self.label.append(self.m)\n",
    "            #if self.m == 0:\n",
    "                #self.label.append('Category1')\n",
    "            #if self.m == 1:\n",
    "                #self.label.append('Category2')\n",
    "            #if self.m == 2:\n",
    "                #self.label.append('Category3')\n",
    "        self.label=np.array(self.label)\n",
    "        return self\n",
    "    \n",
    "    #Crop image from 424x424 to 160x160. To do we crop axes from {x=0, y=0, x=424, y=424 } => {x=132, y=132, x=292, 400=292}\n",
    "    def crop(self, pixels_to_keep = 160):\n",
    "        for galaxyPic in self.images:\n",
    "            #Cast as int in order to use variables in the slicing indices\n",
    "            center = int(424/2)\n",
    "            dim = int(pixels_to_keep/2)\n",
    "            cropmin = center - dim\n",
    "            cropmax = center + dim\n",
    "            self.cropped_images.append(galaxyPic[cropmin:cropmax, cropmin:cropmax])\n",
    "        return self\n",
    "\n",
    "    #function that takes an image and scales the entire image to its new size (unlike crop, image stays intact). \n",
    "    def scale(self, new_size = 16):\n",
    "        for galaxyPic in self.cropped_images:\n",
    "            dimensions = (int(new_size), int(new_size))\n",
    "            self.scaled_images.append(cv2.resize(galaxyPic, dimensions))\n",
    "        return self\n",
    "    \n",
    "    #function that crops out the four 8x8 patches that compose each image.\n",
    "    def patch(self, p_size=8):\n",
    "        for galaxyPic in self.scaled_images:\n",
    "            #Gets the center for each of the four patches\n",
    "            for i in (4, 12):\n",
    "                for j in (4, 12):\n",
    "                    patch_x = i\n",
    "                    patch_y = j\n",
    "                    dim = int(p_size/2)\n",
    "                    patchminx = patch_x - dim\n",
    "                    patchminy = patch_y - dim\n",
    "                    patchmaxx = patch_x + dim\n",
    "                    patchmaxy = patch_y + dim\n",
    "                    self.patches.append(galaxyPic[patchminx:patchmaxx, patchminy:patchmaxy])\n",
    "        return self\n",
    "    #function that sums the values for the different filters and\n",
    "    #flatten the 4x4 matrixes for each patch to a 1x16 vector\n",
    "    def makevector(self):\n",
    "        self.newpatches = np.sum(self.patches, axis = 3)\n",
    "        self.patchvector = []\n",
    "        for i in self.newpatches:\n",
    "            self.patchvector.append(np.matrix.flatten(i).tolist())\n",
    "        self.patchvector=np.array(self.patchvector)\n",
    "        return self\n",
    "    \n",
    "        \n",
    "    ## Function that normalizes the pixels. Takes vstack of patches as input\n",
    "    def normalize(self):\n",
    "        temp1 = self.patchvector - self.patchvector.mean(1, keepdims=True)\n",
    "        temp2 = np.sqrt(self.patchvector.var(1, keepdims=True) + 20)\n",
    "        self.patchvector = temp1/temp2\n",
    "        return self\n",
    "    ## Function that runs ZCA whitening\n",
    "    def whiten(self):\n",
    "        cov = np.cov(self.patchvector, rowvar=0)\n",
    "        self.mean = self.patchvector.mean(0, keepdims=True)\n",
    "        d, v = np.linalg.eig(cov)\n",
    "        self.p = np.dot(v, np.dot(np.diag(np.sqrt(1 / (d + 0.1))), v.T))\n",
    "        self.patchvector = np.dot(self.patchvector - self.mean, self.p)\n",
    "        return self\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#To avoid empty clusters eed to initialize clusters from a Normal distribution \n",
    "#and normalize them to unit length?\n",
    "def Kmeans(L, k = 500, iters = 25, batch_size = 1000):\n",
    "    L2 = np.sum(L**2, 1, keepdims=True)\n",
    "    #initialize centroids\n",
    "    centroids = np.random.randn(k, L.shape[1]) * 0.1\n",
    "    for iteration in range(1, iters+1):\n",
    "        c2 = np.sum(centroids**2, 1, keepdims=True)\n",
    "        summation = np.zeros((k, L.shape[1]))\n",
    "        counts = np.zeros((k, 1))\n",
    "        loss = 0\n",
    "        for i in range(0, L.shape[0], batch_size):\n",
    "            last_index = min(i + batch_size, L.shape[0])\n",
    "            m = last_index - i\n",
    "\n",
    "            # shape (k, batch_size) - shape (k, 1)\n",
    "            tmp = np.dot(centroids, L[i:last_index, :].T) - c2\n",
    "            # shape (batch_size, )\n",
    "            indices = np.argmax(tmp, 0)\n",
    "            # shape (1, batch_size)\n",
    "            val = np.max(tmp, 0, keepdims=True)\n",
    "\n",
    "            loss += np.sum((0.5 * L2[i:last_index]) - val.T)\n",
    "\n",
    "            # Don't use a sparse matrix here\n",
    "            S = np.zeros((batch_size, k))\n",
    "            S[range(batch_size), indices] = 1\n",
    "\n",
    "            # shape (k, n_pixels)\n",
    "            this_sum = np.dot(S.T, L[i:last_index, :])\n",
    "            summation += this_sum\n",
    "\n",
    "            this_counts = np.sum(S, 0, keepdims=True).T\n",
    "            counts += this_counts \n",
    "            \n",
    "        centroids = summation / counts\n",
    "        \n",
    "        bad_indices = np.where(counts == 0)[0]\n",
    "        centroids[bad_indices, :] = 0\n",
    "    return centroids\n",
    "\n",
    "\n",
    "\n",
    "#Testing the class by creating a 'galaxyPic' object, cropping it, scaling it, extracting patches, making the \n",
    "#patch vectors, normalizing and whitening the pixel values. \n",
    "galaxyPics = GetImage()\n",
    "galaxyPics.getLabels()\n",
    "galaxyPics.crop()\n",
    "galaxyPics.scale()\n",
    "galaxyPics.patch()\n",
    "galaxyPics.makevector()\n",
    "galaxyPics.normalize()\n",
    "galaxyPics.whiten()\n",
    "\n",
    "#Making a dictionnary of centroids from our patch vectors\n",
    "dictionnary = Kmeans(galaxyPics.patchvector)\n",
    "#We then use this dictionnary to create features for each patch vector\n",
    "features = []\n",
    "for i in galaxyPics.patchvector:\n",
    "    features.append(np.matmul(dictionnary, i))\n",
    "features = np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionnary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Binarize our labels for the training data\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "y_dense = LabelBinarizer().fit_transform(galaxyPics.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4, 500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Making tuples of features for each image form the patch features\n",
    "truefeatures=[]\n",
    "for i in range(int(len(features) / 4)) :\n",
    "    truefeatures.append((features[4*i], features[4*i+1], features[4*i+2], features[4*i+3]))\n",
    "np.array(features).shape\n",
    "truefeatures = np.array(truefeatures)\n",
    "truefeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reshaping our features for our multiclass algorithm in the next cell\n",
    "nsamples, nx, ny = truefeatures.shape\n",
    "truefeatures = truefeatures.reshape((nsamples,nx*ny))\n",
    "###Separating the training data and test data for our multiclass model\n",
    "train_x = truefeatures[:8000]\n",
    "train_y = galaxyPics.label[:8000]\n",
    "test_x = truefeatures[8000:10000]\n",
    "test_y = galaxyPics.label[8000:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creating our multiclass model using sklearn\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "model=OneVsRestClassifier(SVC(random_state=0, max_iter=50000, probability=True)).fit(train_x, train_y)\n",
    "predictions = model.predict(test_x)\n",
    "predictproba = model.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.15\n"
     ]
    }
   ],
   "source": [
    "## Function for testing accuracy of predictions without using the probabilities\n",
    "def testAccuracy(preds, labels):\n",
    "    count = 0\n",
    "    for i in range(len(preds)):\n",
    "        if(preds[i] == labels[i]):\n",
    "            count += 1\n",
    "    final = 100*(count/len(labels))\n",
    "    return print(\"Accuracy: %.2f\" % (final))\n",
    "testAccuracy(predictions, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  76.33715876521177\n"
     ]
    }
   ],
   "source": [
    "### Function that tests the accuracy using the Root Mean Squared Method\n",
    "###Here we use the probabilities that an image belongs in a cluster to get a better\n",
    "###value of accuracy\n",
    "def testRMS(preds, labels):\n",
    "    count = 0\n",
    "    N = len(preds) * 3\n",
    "    for i in range(len(preds)):\n",
    "        for j in range(len(preds[0])):\n",
    "            count += (preds[i][j] - labels[i][j])**2\n",
    "    return print(\"Accuracy: \", 100*(1-np.sqrt(count/N)))\n",
    "testRMS(predictproba, galaxyPics.solutions[8000:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
